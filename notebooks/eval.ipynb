{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "ds = load_dataset(\"commaai/commavq\", num_proc=40);\n",
    "files = ds['40']['path'] # 40 is the val set\n",
    "\n",
    "BOS_TOKEN = 1024\n",
    "TOKENS_PER_FRAME = 129\n",
    "BS = 10\n",
    "CONTEXT_SIZE_FRAMES = 20\n",
    "N_FRAMES = 1200\n",
    "N = N_FRAMES - 20\n",
    "\n",
    "# Create the data slicing here \n",
    "# 59 non-overlapping slices of 20 frames (we drop the last one)\n",
    "# The target is just the slice shifted by 1\n",
    "indices = np.arange(0, N*TOKENS_PER_FRAME)\n",
    "indices = np.array(np.split(indices, N//CONTEXT_SIZE_FRAMES))\n",
    "# batch them\n",
    "indices = [indices[i:i+BS] for i in range(0, len(indices), BS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_losses = []\n",
    "\n",
    "pbar = tqdm(files)\n",
    "for f in pbar:\n",
    "  tokens = np.load(f)\n",
    "  tokens = tokens.reshape(N_FRAMES, TOKENS_PER_FRAME-1) # TOKENS_PER_FRAME includes the BOS token\n",
    "  tokens = np.c_[np.ones(len(tokens), dtype=np.int64)*BOS_TOKEN, tokens]\n",
    "  tokens = tokens.reshape(-1)\n",
    "  tokens = torch.from_numpy(tokens).long().cuda()\n",
    "  losses, sizes = [], []\n",
    "  for ii in indices:\n",
    "    with torch.no_grad(): # potentially add AMP context etc.\n",
    "      x = tokens[ii.ravel()]\n",
    "      x = x.reshape(ii.shape[0], ii.shape[1])\n",
    "      \n",
    "      # your model here!\n",
    "      pred = model(x)\n",
    "\n",
    "      y = tokens[ii.ravel()+1]\n",
    "      y = y.reshape(ii.shape[0], ii.shape[1])\n",
    "      loss = F.cross_entropy(pred.reshape(-1, pred.size(-1)), y.reshape(-1)).detach().cpu().numpy() * ii.shape[0]\n",
    "      \n",
    "      losses.append(loss)\n",
    "      sizes.append(ii.shape[0])\n",
    "  \n",
    "  total_loss = np.sum(losses)/np.sum(sizes)\n",
    "  total_losses.append(total_loss)\n",
    "  pbar.set_description(f\"total loss {np.mean(total_losses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
